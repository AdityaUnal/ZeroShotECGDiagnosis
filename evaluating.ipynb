{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings \n",
    "\n",
    "import os\n",
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from transformers import pipeline\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import wfdb\n",
    "import neurokit2 as nk\n",
    "import scipy.stats as stats\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "\n",
    "from typing import List,Any,Dict\n",
    "from langchain_core.vectorstores.base import VectorStore\n",
    "from langchain_core.documents import Document\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name,model_kwargs={'device':'cuda'}) \n",
    "max_length = embedding_model._client.tokenizer.model_max_length - 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if not chatmodel change to Chatprompttempelate instead of PromptTempelate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "eval_model_name = \"google/gemma-2-2b-it\"\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(eval_model_name)\n",
    "eval_model = AutoModelForCausalLM.from_pretrained(eval_model_name)\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=eval_model,\n",
    "    device_map=\"auto\",\n",
    "    tokenizer=eval_tokenizer,\n",
    "    return_full_text = False\n",
    ")\n",
    "\n",
    "\n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=pipe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_page(text: str) -> bool:\n",
    "    text = text.strip()\n",
    "    if len(text) < 50:\n",
    "        return False\n",
    "    if \"TEST\" in text and len(set(text.split())) <= 5:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# --- Step 1: Delete existing DB if any\n",
    "db_path = os.path.join(os.getcwd(), \"chroma_db\")\n",
    "try:\n",
    "    chroma_client = chromadb.PersistentClient(path=db_path)\n",
    "    chroma_client.delete_collection(name='Book_embeddings')\n",
    "except Exception as e:\n",
    "    print(f\"DB deletion error (ignored): {e}\")\n",
    "\n",
    "\n",
    "# --- Step 2: Load PDFs and filter\n",
    "pdf_paths = [\n",
    "    'books/12_lead_ecg_the_art_of_interpretation.pdf',\n",
    "    'books/jane-huff-ecg-workout-exercises-in-arrhythmia-interpretation.pdf'\n",
    "]\n",
    "\n",
    "split_docs = []\n",
    "for pdf in pdf_paths:\n",
    "    loader = PyPDFLoader(os.path.join(os.getcwd(), pdf))\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Filter junk pages before splitting\n",
    "    docs = [doc for doc in docs if is_valid_page(doc.page_content)]\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500, chunk_overlap=100, length_function=len\n",
    "    )\n",
    "    documents = text_splitter.split_documents(documents=docs)\n",
    "    split_docs.extend(documents)\n",
    "\n",
    "# --- Step 3: Create Chroma vector store\n",
    "vector_store = Chroma.from_documents(\n",
    "    split_docs,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=db_path,\n",
    "    collection_name='Book_embeddings'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature extraction and refine feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "diseases = {\"ST/T segment change (STTC)\", \"myocardial infarction(MI)\", \"conduction disturbance (CD)\", \"hypertrophy(HYP)\"}\n",
    "diagnosis_guidance = defaultdict(str)\n",
    "guiding_prompt = ChatPromptTemplate[(\n",
    "                (\"system\",\"You are an expert literature retriever\"),\n",
    "                (\"human\",\"Create a diagnosis guidance to interpret {disease} related arrhytmias in a 12-lead ecg system.\"),\n",
    "                )]\n",
    "create_diagnosis_guidance = create_stuff_documents_chain(llm=llm,prompt = guiding_prompt,)\n",
    "\n",
    "for disease in diseases:\n",
    "    query = f\"How to interpret {disease} related arrhythmias in a 12-lead ecg? \"\n",
    "    retrieved_context = retriever.invoke(query)\n",
    "    docs = [doc.page_content for doc in docs]\n",
    "    # See output format\n",
    "    diagnosis_guidance[disease] = create_diagnosis_guidance.invoke({\"context\":docs,\"disease\":disease})\n",
    "retrieved_context_NORM = retriever.invoke(\"How to interpret if a person does not have any heart arrhytmia using 12-lead ecg system\")\n",
    "NORM_docs = [doc.page_content for doc in retrieved_context_NORM]\n",
    "diagnosis_guidance[\"NORM\"] = create_diagnosis_guidance(llm = llm, prompt = \"Create a diagnosis guidance to interpret if a person does not have any related arrhytmias in a 12-lead ecg system \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass_to_superclass = {\n",
    "    \"NORM\": \"NORM\",\n",
    "    \"NSR\": \"NORM\",  # Normal Sinus Rhythm\n",
    "    \"NML\": \"NORM\",  # Normal ECG\n",
    "    \"LAFB/LPFB\": \"CD\", \"IRBBB\": \"CD\", \"ILBBB\": \"CD\", \"CLBBB\": \"CD\", \"CRBBB\": \"CD\", \"_AVB\": \"CD\", \"IVCB\": \"CD\", \"WPW\": \"CD\",\n",
    "    \"LVH\": \"HYP\", \"RHV\": \"HYP\", \"LAO/LAE\": \"HYP\", \"RAO/RAE\": \"HYP\", \"SEHYP\": \"HYP\",\n",
    "    \"AMI\": \"MI\", \"IMI\": \"MI\", \"LMI\": \"MI\", \"PMI\": \"MI\",\n",
    "    \"ISCA\": \"STTC\", \"ISCI\": \"STTC\", \"ISC_\": \"STTC\", \"STTC\": \"STTC\", \"NST_\": \"STTC\"\n",
    "}\n",
    "\n",
    "statements_path = os.path.join(os.getcwd(),\"physionet.org/files/ptb-xl-plus/1.0.1/labels/ptbxl_statements.csv\")\n",
    "\n",
    "statements_df = pd.read_csv(statements_path)\n",
    "\n",
    "count = {\n",
    "    \"NORM\": 0,\n",
    "    \"CD\": 0,\n",
    "    \"HYP\": 0,\n",
    "    \"MI\": 0,\n",
    "    \"STTC\": 0\n",
    "}\n",
    "diagnosis_statements = defaultdict(list)\n",
    "for idx, row in statements_df.iterrows():\n",
    "    ecg_id = row['ecg_id']\n",
    "    statements = ast.literal_eval(row['scp_codes'])\n",
    "    for statement in statements:\n",
    "        if statement[0] in subclass_to_superclass:\n",
    "            if(count[subclass_to_superclass[statement[0]]] < 10):\n",
    "                count[subclass_to_superclass[statement[0]]] += 1\n",
    "                if(ecg_id<=9):\n",
    "                    diagnosis_statements[f\"0000{ecg_id}_lr\"].append(subclass_to_superclass[statement[0]])\n",
    "                elif(ecg_id<100 and ecg_id>9):\n",
    "                    diagnosis_statements[f\"000{ecg_id}_lr\"].append(subclass_to_superclass[statement[0]])\n",
    "                else:\n",
    "                    diagnosis_statements[f\"00{ecg_id}_lr\"].append(subclass_to_superclass[statement[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_full_ecg_features(record):\n",
    "    \"\"\"\n",
    "    Extracts and describes key ECG features from each lead in the multi-lead ECG signal.\n",
    "    \n",
    "    Parameters:\n",
    "    - record: ECG data record containing multi-lead ECG signals and sampling rate.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary containing descriptive statistics and fiducial features for each lead.\n",
    "    \"\"\"\n",
    "    # Extract the ECG signal, lead names, and sampling rate\n",
    "    signals = record.p_signal  # multi-lead ECG signal (time x leads)\n",
    "    leads = record.sig_name    # Lead names (e.g., ['I', 'II', ..., 'V6'])\n",
    "    sampling_rate = record.fs  # Sampling rate of the ECG signal (in Hz)\n",
    "    all_lead_features = {}\n",
    "\n",
    "    # Iterate over each ECG lead\n",
    "    for lead_idx, lead_name in enumerate(leads):\n",
    "        lead_signal = signals[:, lead_idx]  # Extract signal for the current lead\n",
    "\n",
    "        # Basic Statistics with safety checks\n",
    "        mean_val = np.mean(lead_signal) if lead_signal.size > 0 else None\n",
    "        variance = np.var(lead_signal) if lead_signal.size > 0 else None\n",
    "        iqr = stats.iqr(lead_signal) if lead_signal.size > 1 else None\n",
    "        min_val = np.min(lead_signal) if lead_signal.size > 0 else None\n",
    "        max_val = np.max(lead_signal) if lead_signal.size > 0 else None\n",
    "\n",
    "        # Process ECG signal to extract fiducial points (R, P, T peaks)\n",
    "        try:\n",
    "            processed_signals, _ = nk.ecg_process(lead_signal, sampling_rate=sampling_rate)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping lead {lead_name} due to ECG processing error: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Extract Peaks: R, P, T peaks\n",
    "        r_peaks = np.where(processed_signals[\"ECG_R_Peaks\"] == 1)[0]\n",
    "        p_peaks = np.where(processed_signals[\"ECG_P_Peaks\"] == 1)[0]\n",
    "        t_peaks = np.where(processed_signals[\"ECG_T_Peaks\"] == 1)[0]\n",
    "\n",
    "        # Amplitudes of the R, P, and T peaks\n",
    "        r_amplitudes = lead_signal[r_peaks].tolist() if len(r_peaks) > 0 else []\n",
    "        p_amplitudes = lead_signal[p_peaks].tolist() if len(p_peaks) > 0 else []\n",
    "        t_amplitudes = lead_signal[t_peaks].tolist() if len(t_peaks) > 0 else []\n",
    "\n",
    "        # Calculate RR Intervals (time between consecutive R-peaks) and Heart Rate\n",
    "        rr_intervals = np.diff(r_peaks) / sampling_rate if len(r_peaks) > 1 else []\n",
    "        mean_rr = np.mean(rr_intervals) if len(rr_intervals) > 0 else None\n",
    "        heart_rate = 60 / mean_rr if mean_rr else None\n",
    "\n",
    "        # Function to calculate descriptive statistics safely\n",
    "        def safe_stats(arr):\n",
    "            return {\n",
    "                \"mean\": np.mean(arr) if len(arr) > 0 else None,\n",
    "                \"variance\": np.var(arr) if len(arr) > 0 else None,\n",
    "                \"iqr\": stats.iqr(arr) if len(arr) > 1 else None,\n",
    "                \"min\": np.min(arr) if len(arr) > 0 else None,\n",
    "                \"max\": np.max(arr) if len(arr) > 0 else None\n",
    "            }\n",
    "\n",
    "        # Organize features into a dictionary with descriptive names\n",
    "        all_lead_features[lead_name] = {\n",
    "            \"Statistical Features\": {\n",
    "                \"Mean Voltage (mV)\": mean_val,\n",
    "                \"Voltage Variance\": variance,\n",
    "                \"Interquartile Range (IQR)\": iqr,\n",
    "                \"Minimum Voltage (mV)\": min_val,\n",
    "                \"Maximum Voltage (mV)\": max_val,\n",
    "            },\n",
    "            \"ECG Fiducial Features\": {\n",
    "                \"R-Wave Amplitudes (mV)\": safe_stats(r_amplitudes),\n",
    "                \"P-Wave Amplitudes (mV)\": safe_stats(p_amplitudes),\n",
    "                \"T-Wave Amplitudes (mV)\": safe_stats(t_amplitudes),\n",
    "                \"RR Intervals (seconds)\": safe_stats(rr_intervals),\n",
    "                \"Mean RR Interval (seconds)\": mean_rr,\n",
    "                \"Heart Rate (BPM)\": heart_rate\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Generate a descriptive text for each lead\n",
    "    lead_descriptions = []\n",
    "    for lead, feat in all_lead_features.items():\n",
    "        parts = [f\"Lead {lead}:\"]\n",
    "\n",
    "        # Iterate over all categories of features (Statistical and Fiducial)\n",
    "        for category_name, category in feat.items():\n",
    "            parts.append(f\"  {category_name}:\")\n",
    "            for key, val in category.items():\n",
    "                if isinstance(val, dict):\n",
    "                    # If value is a dict, expand and display each sub-statistic\n",
    "                    sub = \", \".join(f\"{k}: {round(v, 3) if isinstance(v, float) else v}\" for k, v in val.items())\n",
    "                    parts.append(f\"    {key} ({sub})\")\n",
    "                else:\n",
    "                    # Format the main feature value\n",
    "                    v = round(val, 3) if isinstance(val, float) else val\n",
    "                    parts.append(f\"    {key}: {v}\")\n",
    "\n",
    "        lead_descriptions.append(\"\\n\".join(parts))\n",
    "\n",
    "    # Combine all lead descriptions into a final output string\n",
    "    full_description = \"\\n\\n\".join(lead_descriptions)\n",
    "    \n",
    "    return full_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diagnosisOutput(BaseModel):\n",
    "    disease_name : str\n",
    "    Result: bool\n",
    "    Explanation: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose(record, disease:str):\n",
    "    feature_prompt = ChatPromptTemplate[(\n",
    "        (\"system\",\"You are an ECG expert and can calculate fiducial points and segements across different leads.\"),\n",
    "        (\"human\",\"Retrieve the relevant information from {features} required to interpret {disease} heart arrhythmias. Use this {diagnosis_guidance}\")\n",
    "    )]\n",
    "    patient_features = extract_full_ecg_features(record)\n",
    "    create_feature_prompt = create_stuff_documents_chain(llm = llm, prompt = feature_prompt)\n",
    "    feature_prompt = create_feature_prompt.invoke({\n",
    "                    \"features\": patient_features,\n",
    "                    \"disease\": disease,\n",
    "                    \"diagnosis_guidance\": diagnosis_guidance[disease]\n",
    "                    \n",
    "                })\n",
    "    diagnosis_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are a medical expert in heart arrhythmia diagnosis.\n",
    "\n",
    "        DISEASE TO DIAGNOSE: {input}\n",
    "        MEDICAL CONTEXT: {context}\n",
    "        PATIENT'S MEASURED FEATURES: {patient_features}\n",
    "\n",
    "        Based on medical literature and the patient's measurements, determine whether the patient has {input}.\n",
    "\n",
    "        Please return ONLY a JSON object with the following fields:\n",
    "\n",
    "        - disease_name: Name of the disease (must match the input)\n",
    "        - Result: true or false, depending on whether the patient has the disease\n",
    "        - Explanation: Justification for the decision\n",
    "\n",
    "        Example output:\n",
    "        {{\n",
    "        \"disease_name\": \"NORM\",\n",
    "        \"Result\": False,\n",
    "        \"Explanation\": \"The ECG shows significant abnormalities including ST segment elevation, inverted T waves, and abnormal RS complexes, indicating the presence of arrhythmias and excluding a normal ECG\"\n",
    "        }}\n",
    "\n",
    "        ⚠️ Do not add any text before or after the JSON block.\n",
    "        Return only the JSON in valid format.\n",
    "        \"\"\")\n",
    "    parser = JsonOutputParser(pydantic_object=diagnosisOutput)\n",
    "    final_chain = diagnosis_prompt | llm | parser\n",
    "    \n",
    "    result = final_chain.invoke({\n",
    "        \"input\": disease,\n",
    "        \"context\": diagnosis_guidance[disease],\n",
    "        \"patient_features\": patient_features\n",
    "    })\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(os.path.join(os.getcwd(),\"ptb-xl+/features/old/12sl_features.csv\"))\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "df = pd.DataFrame()\n",
    "for ecg_id, statements in diagnosis_statements.items():\n",
    "    for _,features in features_df.iterrows():\n",
    "        if features['ecg_id'] == ecg_id:\n",
    "            results = []\n",
    "            for disease in diseases:\n",
    "                response = diagnose(features=features,disease=disease)\n",
    "                if(response.Result==True and disease in statements):\n",
    "                    tp +=1\n",
    "                elif(response.Result==True):\n",
    "                    tn +=1\n",
    "                elif(response.Result==False and disease in statements):\n",
    "                    fn +=1\n",
    "                else:\n",
    "                    fp +=1\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) != 0 else 0\n",
    "precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "print(\"Accuracy : \", accuracy)\n",
    "print(\"Precision : \", precision)\n",
    "print(\"Recall : \", recall)\n",
    "print(\"F1 Score : \", f1_score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
